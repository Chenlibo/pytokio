{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAMI Demo\n",
    "\n",
    "This notebook demonstrates how to generate an UMAMI plot from a .csv file that has been generated by the `summarize_job.py` script included with pytokio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas\n",
    "import datetime\n",
    "import tokio.tools.umami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We _must_ include `parse_dates` for the column which will be passed as each `UmamiMetric`'s timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pandas.read_csv('sample_summary.csv',\n",
    "                     parse_dates=['_datetime_start', '_datetime_end'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter data\n",
    "\n",
    "We can select jobs that only match certain criteria by performing boolean operators on the DataFrame to generate filters.  We can then combine these filters using the `&` operator.\n",
    "\n",
    "In this example, we apply the following filters:\n",
    "\n",
    "1. Select only jobs that did more writes than reads.  The `darshan_biggest_{read,write}_api_bytes` keys contain the total number of bytes read or written by any single I/O API (POSIX or MPI-IO).\n",
    "\n",
    "2. Select only jobs that performed most of their I/O to the file system mounted at `/scratch2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### Select only jobs that did more writes than reads\n",
    "filtered_indices = df['darshan_biggest_write_api_bytes'] > df['darshan_biggest_read_api_bytes']\n",
    "\n",
    "### Select jobs in a specific time range\n",
    "filtered_indices &= df['_datetime_start'] > datetime.datetime(2017, 2, 21)\n",
    "filtered_indices &= df['_datetime_start'] < datetime.datetime(2017, 3, 3, 12, 0, 0)\n",
    "\n",
    "### and also select only jobs whose I/O went to a file system mounted at a specific place.\n",
    "### Note that we have to check the type because Pandas will load empty CSV values as NaN,\n",
    "### which cannot be .startswith()ed.\n",
    "filtered_indices &= [ type(x) == str and x.startswith('/scratch2') for x in df['darshan_biggest_write_fs'] ]\n",
    "\n",
    "\n",
    "### Filter out dates where Darshan says we wrote more than Lustre thinks\n",
    "filtered_indices &= df['darshan_total_gibs_posix'] <= df['lmt_tot_gibs_written']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now view a few example rows from our filtered data.  Note that we use `.T` to transpose the example rows just so you can see all of the metrics contained in this DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[filtered_indices].head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Umami object\n",
    "\n",
    "We want to look at the following metrics:\n",
    "\n",
    "1. `darshan_agg_perf_by_slowest_posix`, converted to GiB/s\n",
    "2. `darshan_total_gibs_posix` / ( `lmt_tot_gibs_read` + `lmt_tot_gibs_written` )\n",
    "3. `fshealth_ost_most_full_pct`\n",
    "4. `lmt_ave_mds_cpu`\n",
    "5. `lmt_max_oss_cpu`\n",
    "\n",
    "For each one, we create an `UmamiMetric` object, then we build the `Umami` object from them.  `UmamiMetric` objects can be given anything list-like (i.e., can be sliced in exactly one dimension), or `pandas.Series` objects.  In this example, we are passing it `pandas.Series` objects that are pulled straight out of our `df` DataFrame.\n",
    "\n",
    "Note that the following code is expanded out to make it easy to read; in practice, it's more concise to iteratively create and add new `UmamiMetric`s to the parent `Umami` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric1 = tokio.tools.umami.UmamiMetric(\n",
    "    timestamps=df[filtered_indices]['_datetime_start'],\n",
    "    values=df[filtered_indices]['darshan_agg_perf_by_slowest_posix'] / 1024.0,\n",
    "    label=\"Performance (GiB/sec)\",\n",
    "    big_is_good=True)\n",
    "\n",
    "metric2 = tokio.tools.umami.UmamiMetric(\n",
    "    timestamps=df[filtered_indices]['_datetime_start'],\n",
    "    values=df[filtered_indices]['darshan_total_gibs_posix'] /\n",
    "        (df[filtered_indices]['lmt_tot_gibs_read'] + df[filtered_indices]['lmt_tot_gibs_written']),\n",
    "    label=\"Coverage Factor\",\n",
    "    big_is_good=True)\n",
    "\n",
    "metric3 = tokio.tools.umami.UmamiMetric(\n",
    "    timestamps=df[filtered_indices]['_datetime_start'],\n",
    "    values=df[filtered_indices]['fshealth_ost_most_full_pct'],\n",
    "    label=\"OST Fullness\",\n",
    "    big_is_good=False)\n",
    "\n",
    "metric4 = tokio.tools.umami.UmamiMetric(\n",
    "    timestamps=df[filtered_indices]['_datetime_start'],\n",
    "    values=df[filtered_indices]['lmt_max_oss_cpu'],\n",
    "    label=\"Highest OSS CPU Load\",\n",
    "    big_is_good=False)\n",
    "\n",
    "metric5 = tokio.tools.umami.UmamiMetric(\n",
    "    timestamps=df[filtered_indices]['_datetime_start'],\n",
    "    values=df[filtered_indices]['lmt_ave_mds_cpu'],\n",
    "    label=\"Average MDS CPU Load\",\n",
    "    big_is_good=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct an `Umami` object with the five metrics we defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "umami = tokio.tools.umami.Umami()\n",
    "umami['performance'] = metric1\n",
    "umami['cf'] = metric2\n",
    "umami['fullness'] = metric3\n",
    "umami['max_oss_cpu'] = metric4\n",
    "umami['avg_mds_cpu'] = metric5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the UMAMI\n",
    "\n",
    "The most obvious thing to do with an UMAMI is plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = umami.plot()\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its data can also be presented as a DataFrame.  Note that the `UmamiMetric` metadata (the label and whether bigger values are better or not) are lost when we do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "umami.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Umami` and `UmamiMetric` objects also serialize reasonably well.  The parent object can be converted either to a dictionary or a json string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print umami.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print umami.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
